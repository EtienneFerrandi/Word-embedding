{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word embedding ngram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZd71hp9bWZRFZKiM8tXtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EtienneFerrandi/Word-embedding/blob/main/Word_embedding_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOFP7H9YncMX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkUv4up-oRjd",
        "outputId": "6ef39437-2d3a-4011-854b-a508b59b86bd"
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff6a7a71bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSP1olV4oT-h",
        "outputId": "8a042dc9-92e8-4eb6-fe8e-52969180878e"
      },
      "source": [
        "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
        "embeds = nn.Embedding(2, 5)\n",
        "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
        "hello_embed = embeds(lookup_tensor)\n",
        "print(hello_embed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2857,  0.6898, -0.6331,  0.8795, -0.6842]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZea8n9ErJ4l"
      },
      "source": [
        "CONTEXT_SIZE = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww4-Qkd1rJ9h"
      },
      "source": [
        "EMBEDDING_DIM = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7X3YfaUoUBg"
      },
      "source": [
        "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2msxiyK4rAQM",
        "outputId": "7721baf5-ef95-4657-f603-2372b7eaa1ad"
      },
      "source": [
        "ngrams = [\n",
        "    (\n",
        "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
        "        test_sentence[i]\n",
        "    )\n",
        "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
        "]\n",
        "print(ngrams[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['forty', 'When'], 'winters'), (['winters', 'forty'], 'shall'), (['shall', 'winters'], 'besiege')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9sV-x4_rAVd"
      },
      "source": [
        "vocab = set(test_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnLEtXLrrAZd"
      },
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNMojaAgoUF4"
      },
      "source": [
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OGhtrYp-mAy"
      },
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLHoi614_Iio",
        "outputId": "1a1d0db2-5500-40b9-e152-67f9aa75c3a7"
      },
      "source": [
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for context, target in ngrams:\n",
        "              context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "              model.zero_grad()\n",
        "              log_probs = model(context_idxs)\n",
        "              loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[516.1814589500427, 513.3693492412567, 510.57821679115295, 507.80692195892334, 505.05404806137085, 502.31887888908386, 499.59962725639343, 496.8926088809967, 494.198885679245, 491.5178225040436]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFWJyOrS_Imo",
        "outputId": "366e74cd-7d7a-474a-c468-99a9dacee88a"
      },
      "source": [
        "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4497,  0.4590,  0.7382, -1.1819,  0.2708, -0.4747,  0.5774,  0.1755,\n",
            "         1.0462, -1.5931], grad_fn=<SelectBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sTBFBqO_IsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAwFeLA4_Iwy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t1zSFxH-mGe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}